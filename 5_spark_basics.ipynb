{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Spark basics practice</h1>\n",
    "<li>The code in the next cell extracts covid data from New York State's covid repository</li>\n",
    "<li>The extracted data is stored in an RDD containing an Array of (String, String,Int,Int) matching (date, borough, positive cases, tests) for each day since March 1st 2020 (the data is ordered by time)</li>\n",
    "<li>Use this RDD to answer the questions below</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://localhost:4041\n",
       "SparkContext available as 'sc' (version = 3.2.0, master = local[*], app id = local-1646000884172)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "counties: Array[String] = Array(New+York, Bronx, Kings, Queens, Richmond)\n",
       "base_url: String = https://health.data.ny.gov/resource/xdss-u53e.json?County=\n",
       "urls: Array[String] = Array(https://health.data.ny.gov/resource/xdss-u53e.json?County=New+York, https://health.data.ny.gov/resource/xdss-u53e.json?County=Bronx, https://health.data.ny.gov/resource/xdss-u53e.json?County=Kings, https://health.data.ny.gov/resource/xdss-u53e.json?County=Queens, https://health.data.ny.gov/resource/xdss-u53e.json?County=Richmond)\n",
       "results: Array[String] =\n",
       "Array(\"[{\"test_date\":\"2020-03-01T00:00:00.000\",\"county\":\"New York\",\"new_positives\":\"0\",\"cumulative_number_of_positives\":\"0\",\"total_number_of_tests\":\"0\",\"cumulative_number_of_tests\":\"0\"}\n",
       ",{\"test_date\":\"2020-03-02T00:00:00.000\",\"county\":\"New York\",\"new_positives...\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val counties = Array(\"New+York\", \"Bronx\",\"Kings\",\"Queens\",\"Richmond\")\n",
    "val base_url = \"https://health.data.ny.gov/resource/xdss-u53e.json?County=\"\n",
    "val urls = counties.map(a => base_url+a)\n",
    "val results = urls.map(u => scala.io.Source.fromURL(u).mkString)\n",
    "val data_rdd = spark.read.json(sc.parallelize(results)).rdd.map(r => (r(4).toString.slice(0,10), r(0).toString,r(3).toString.toInt,r(5).toString.toInt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: org.apache.spark.rdd.RDD[(String, String, Int, Int)] = MapPartitionsRDD[13] at map at <console>:28\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Array[(String, String, Int, Int)] = Array((2020-03-01,New York,0,0), (2020-03-02,New York,0,0), (2020-03-03,New York,0,3))\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question 1</h1>\n",
    "<li>Using <span style=\"color:blue\">reduce</span> calculate the total number of cases and total number of tests in New York City</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYC total: 2270783 positive cases from 48013596 tests\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "total_cases_tests: (Int, Int) = (2270783,48013596)\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val total_cases_tests = data_rdd.map(x => (x._3,x._4)).reduce((a,b) => (a._1+b._1, a._2+b._2))\n",
    "println(\"NYC total: \" + total_cases_tests._1 + \" positive cases from \" + total_cases_tests._2 + \" tests\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question 2</h1>\n",
    "Using <span style=\"color:blue\">reduceByKey</span> calculate the number of cases and total number of tests by borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Richmond: 161960 positive cases from 3043718 tests\n",
      "Kings: 680089 positive cases from 14553145 tests\n",
      "New York: 401978 positive cases from 11563532 tests\n",
      "Bronx: 392556 positive cases from 7089709 tests\n",
      "Queens: 634200 positive cases from 11763492 tests\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cases_tests_by_borough: org.apache.spark.rdd.RDD[(String, (Int, Int))] = ShuffledRDD[16] at reduceByKey at <console>:24\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cases_tests_by_borough = data_rdd.map(x => (x._2, (x._3,x._4))).reduceByKey((a,b) => (a._1+b._1, a._2+b._2))\n",
    "cases_tests_by_borough.foreach(x=> println(x._1 + \": \" + x._2._1 + \" positive cases from \" + x._2._2 + \" tests\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question 3</h1>\n",
    "Using <span style=\"color:blue\">reduceByKey</span> and <a href=\"http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html#sortBy\">sortBy</a> calculate the number of cases and number of tests by month and return an RDD of Array(Month,(cases,tests)) sorted by the number of cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cases_tests_by_month: org.apache.spark.rdd.RDD[(String, (Int, Int))] = MapPartitionsRDD[23] at sortBy at <console>:26\n",
       "res4: Array[(String, (Int, Int))] = Array((01,(809738,7659628)), (12,(576298,7019201)), (04,(200562,3039529)), (03,(169018,3020578)), (02,(150012,4526606)), (11,(86162,4329754)), (08,(66212,3255962)), (09,(58244,3620381)), (05,(53328,2658541)), (10,(51554,4235084)), (07,(31769,2280865)), (06,(17886,2367467)))\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cases_tests_by_month = data_rdd.map(x => (x._1.slice(5,7), (x._3, x._4)))\n",
    "                                   .reduceByKey((a,b) => (a._1+b._1, a._2+b._2))\n",
    "                                   .sortBy(c => c._2._1,false) //descending\n",
    "cases_tests_by_month.collect//.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question 4</h1>\n",
    "Return an RDD of (date,borough,positivity) where positivity is the percentage of tests that are positive. For this problem, you must use the Option case class to handle the case where the divisor is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positivity_double: org.apache.spark.rdd.RDD[(String, String, Double)] = MapPartitionsRDD[36] at map at <console>:24\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//double division, zerodivision handled by nan\n",
    "val positivity_double = data_rdd.map(x => (x._1, x._2, 100.0*x._3/x._4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positivity_int: org.apache.spark.rdd.RDD[(String, String, Option[Int])] = MapPartitionsRDD[52] at map at <console>:24\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//integer division, zerodivision handled using Option cases and None\n",
    "val positivity_int = data_rdd.map(x => (x._1, x._2, try {Some(100*x._3/x._4)} catch {case e: Exception => None}))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question 5</h1>\n",
    "Return the tuple (date,borough,positivity) where the positivity was the highest (use <span style=\"color:blue\">takeOrdered</span>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highest_positive_double: (String, String, Double) = (2020-03-29,Queens,65.69190600522194)\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val highest_positive_double = positivity_double\n",
    "            .takeOrdered(1)(Ordering[Double].reverse.on(x => if (x._3.isNaN) Double.MinValue else x._3))(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highest_positive_int: (String, String, Int) = (2020-03-29,Queens,65)\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val highest_positive_int = positivity_int.map(x => (x._1, x._2, x._3 match {case Some(s) => s case None => Int.MinValue}))\n",
    "                                         .takeOrdered(1)(Ordering[Int].reverse.on(y => y._3))(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
