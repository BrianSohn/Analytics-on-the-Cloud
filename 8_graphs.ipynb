{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:red;font-size:60px\">GraphFrames Assignment</span>\n",
    "<br><br>\n",
    "In this assignment, you need to do the following:\n",
    "<li>Read the file 201710-citibike-tripdata.csv</li>\n",
    "<li>Construct a graph with stations as vertices and trips between stations as edges</li>\n",
    "<li>Vertex Ids are station numbers and Vertex attributes are station names</li>\n",
    "<li>Edge attributes are trip duration (durations are in seconds)</li>\n",
    "<li>Then answer the questions below</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.packages= [\"graphframes:graphframes:0.8.2-spark3.2-s_2.12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://localhost:4043\n",
       "SparkContext available as 'sc' (version = 3.2.0, master = local[*], app id = local-1648710643302)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql._\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.graphframes._\n",
       "import org.apache.spark.graphx._\n",
       "import org.apache.spark.rdd.RDD\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//GraphFrame imports\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.graphframes._\n",
    "\n",
    "\n",
    "//GraphX imports\n",
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Step 1: Construct the graph</span>\n",
    "<br><br>\n",
    "<li>read the data file and drop the header line</li>\n",
    "<li>create a vertex rdd (the union of start stations and end stations</li>\n",
    "<li>create an edge rdd (the trips - start station id, end station id, duration</li>\n",
    "<li>create a graph</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text: org.apache.spark.rdd.RDD[String] = 201710-citibike-tripdata.csv MapPartitionsRDD[1] at textFile at <console>:37\n",
       "text_no_header: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at mapPartitionsWithIndex at <console>:38\n",
       "start_rdd: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[4] at map at <console>:43\n",
       "end_rdd: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[6] at map at <console>:44\n",
       "vertex_rdd: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[10] at distinct at <console>:45\n",
       "edge_rdd: org.apache.spark.rdd.RDD[(String, String, Double)] = MapPartitionsRDD[12] at map at <console>:47\n",
       "vertices: org.apache.spark.sql.DataFrame = [id: string, location: string]\n",
       "edges: org.apache.spark.sql.DataFrame = [src: string, dst: string ... 1 more field]...\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val text = sc.textFile(\"201710-citibike-tripdata.csv\")\n",
    "val text_no_header = text.mapPartitionsWithIndex{ (idx,iter) => if (idx==0) iter.drop(1) else iter}\n",
    "\n",
    "//Construct vertices and edges here\n",
    "\n",
    "//create vertices\n",
    "val start_rdd = text_no_header.map(x => x.split(\",\")).map(y => (y(3), y(4))) //id, name\n",
    "val end_rdd = text_no_header.map(x => x.split(\",\")).map(y => (y(7), y(8))) //id, name\n",
    "val vertex_rdd = (start_rdd union end_rdd).distinct\n",
    "//create edges\n",
    "val edge_rdd = text_no_header.map(x => x.split(\",\")).map(y => (y(3), y(7), y(0).toDouble)) //start_id, end_id, duration\n",
    "\n",
    "//create dataframes\n",
    "val vertices = spark.createDataFrame(vertex_rdd).toDF(\"id\",\"location\")\n",
    "val edges = spark.createDataFrame(edge_rdd).toDF(\"src\",\"dst\",\"dur\")\n",
    "\n",
    "//create graph\n",
    "val g = GraphFrame(vertices,edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Step 2: Basic questions</span>\n",
    "<br><br>\n",
    "\n",
    "<li>How many citibike stations are there in the network?</li>\n",
    "<li>How many trips were made in the month in question?</li>\n",
    "<li>How many trips started and ended at the same station?</li>\n",
    "<li>How many station to station connections are there (at least one edge exists between station i and station j and i is not equal to j)?</li>\n",
    "<li>Your code should print:</li>\n",
    "<pre>\n",
    "Total number of stations: 785\n",
    "Total number of trips.  : 1897592\n",
    "Trips that started and ended at the same station: 33245\n",
    "Number of station to station connections: 107524\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_undirected_graph: (g: org.graphframes.GraphFrame)org.graphframes.GraphFrame\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//You might need this\n",
    "def make_undirected_graph(g: GraphFrame) = {\n",
    "    val u_edge_df = g.find(\"(a)-[]->(b)\")\n",
    "        .select($\"a.id\".as(\"src\"),$\"b.id\".as(\"dst\"))\n",
    "        .withColumn(\"swap\",when(col(\"src\")<col(\"dst\"),col(\"dst\")))\n",
    "        .withColumn(\"dst\",\n",
    "                    when(col(\"swap\").isNotNull,col(\"src\"))\n",
    "                    .otherwise(col(\"dst\")))\n",
    "        .withColumn(\"src\",\n",
    "                    when(col(\"swap\").isNotNull,col(\"swap\"))\n",
    "                   .otherwise(col(\"src\")))\n",
    "        .drop(col(\"swap\"))\n",
    "        .distinct\n",
    "    val u_vertices_df = g.vertices\n",
    "    val u_g = GraphFrame(u_vertices_df,u_edge_df)    \n",
    "    u_g\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "//g.vertices.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "//g.edges.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "//g.find(\"(a)-[]->(a)\").count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g_undirected: org.graphframes.GraphFrame = GraphFrame(v:[id: string, location: string], e:[src: string, dst: string])\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val g_undirected = make_undirected_graph(g)\n",
    "//g_undirected.find(\"(a)-[]->(b)\").filter(\"a.id != b.id\").distinct.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stations: 785\n",
      "Total number of trips.  : 1897592\n",
      "Trips that started and ended at the same station: 33245\n",
      "Number of station to station connections: 107524\n"
     ]
    }
   ],
   "source": [
    "println(\"Total number of stations: \"+ g.vertices.count)\n",
    "println(\"Total number of trips.  : \"+ g.edges.count)\n",
    "println(\"Trips that started and ended at the same station: \"+ g.find(\"(a)-[]->(a)\").count)\n",
    "println(\"Number of station to station connections: \"+ g_undirected.find(\"(a)-[]->(b)\").filter(\"a.id != b.id\").distinct.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Step 3: Find the Station from which most trips originate</span>\n",
    "<br><br>\n",
    "<li>Note that the graph has one edge for each trip (i.e., there are many edges between two vertices)</li>\n",
    "<li>The function <span style=\"color:blue\">outDegrees</span> returns the number of outgoing edges from every vertex</li>\n",
    "<li>Print the name of the station with most originating trips</li>\n",
    "<li>Your code should print:</li>\n",
    "<pre>  \n",
    "The station from which most trips originate is: \"Pershing Square North\"\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The station from which most trips originate is: \"Pershing Square North\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "maxOutId: Any = 519\n",
       "maxOutName: Any = \"Pershing Square North\"\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val maxOutId = g.outDegrees.orderBy(desc(\"outDegree\")).select(\"id\").take(1)(0)(0)\n",
    "val maxOutName = g.vertices.filter($\"id\" === maxOutId).select(\"location\").take(1)(0)(0)\n",
    "\n",
    "println(\"The station from which most trips originate is: \"+maxOutName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">STEP 4: Proportion of trips for each station that start and end at that same station</span>\n",
    "<br><br>\n",
    "<li>Create a GraphX graph from the GraphFrames graph (use the method that retains datatypes)</li>\n",
    "<li>Use aggregateMessages to calculate the number of trips that start and end at the same vertex (for each vertex)</li>\n",
    "<li>Convert the resulting (VertexRDD) to a DataFrame</li>\n",
    "<li>Using join (and select), add the location of the station column to the df</li>\n",
    "<li>Join this df to the out degrees df created earlier</li>\n",
    "<li>Divide the same trips column by the out degrees column and select the appropriate rows</li>\n",
    "<li>Sort the resulting df by this proportion in descending order</li>\n",
    "<li>Your output should be the following dataframe</li>\n",
    "<li>Note: Though you can use aggregateMessages in GraphFrames, you must use the GraphX version for this assignment</li>\n",
    "    \n",
    "<pre>\n",
    "+----+--------------------+-----+---------+-------------------+\n",
    "|  id|            location|trips|outDegree|               prop|\n",
    "+----+--------------------+-----+---------+-------------------+\n",
    "|3488|  \"8D QC Station 01\"|    1|        1|                1.0|\n",
    "|3245|\"NYCBS DEPOT - DE...|    1|        2|                0.5|\n",
    "|3182|\"Yankee Ferry Ter...|  309|      900| 0.3433333333333333|\n",
    "|3254|  \"Soissons Landing\"|  358|     1100|0.32545454545454544|\n",
    "|3342|\"Pioneer St & Ric...|   59|      299|0.19732441471571907|\n",
    "|3477|\"39 St & 2 Ave - ...|   45|      245| 0.1836734693877551|\n",
    "|3532|\"Ditmars Blvd & 1...|   70|      407|  0.171990171990172|\n",
    "|3180|\"Brooklyn Bridge ...|  232|     1354|0.17134416543574593|\n",
    "|3423|\"West Drive & Pro...|  367|     2463|0.14900527811611855|\n",
    "|3636|\"Expansion Wareho...|    1|        8|              0.125|\n",
    "|3302|\"Columbus Ave & W...|   74|      598|0.12374581939799331|\n",
    "|3120|\"Center Blvd & Bo...|   74|      622| 0.1189710610932476|\n",
    "|3514|\"Astoria Park S &...|   34|      299|0.11371237458193979|\n",
    "|3479|      \"Picnic Point\"|   77|      712|0.10814606741573034|\n",
    "|3594|\"Montgomery St & ...|    9|       87|0.10344827586206896|\n",
    "|3524|    \"19 St & 24 Ave\"|   24|      249| 0.0963855421686747|\n",
    "|3349|\"Grand Army Plaza...|  237|     2570|0.09221789883268483|\n",
    "|3333|\"Columbia St & Lo...|    5|       55|0.09090909090909091|\n",
    "|3354|\"3 St & Prospect ...|  142|     1572|0.09033078880407125|\n",
    "|3607|    \"31 Ave & 14 St\"|   10|      113|0.08849557522123894|\n",
    "+----+--------------------+-----+---------+-------------------+\n",
    "only showing top 20 rows\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v: org.apache.spark.rdd.RDD[(Long, String)] = MapPartitionsRDD[79] at map at <console>:38\n",
       "e: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[Double]] = MapPartitionsRDD[85] at map at <console>:39\n",
       "gx: org.apache.spark.graphx.Graph[String,Double] = org.apache.spark.graphx.impl.GraphImpl@2e74eaf1\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Create a GraphX graph from the GraphFrames graph (use the method that retains datatypes)\n",
    "val v = g.vertices.rdd.map(r => (r(0).toString.toLong,r(1).toString))\n",
    "val e = g.edges.rdd.map(r => Edge(r(0).toString.toLong,r(1).toString.toLong,r(2).toString.toDouble))\n",
    "val gx: Graph[String, Double] = Graph(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-----+---------+-------------------+\n",
      "|  id|            location|trips|outDegree|               prop|\n",
      "+----+--------------------+-----+---------+-------------------+\n",
      "|3488|  \"8D QC Station 01\"|    1|        1|                1.0|\n",
      "|3245|\"NYCBS DEPOT - DE...|    1|        2|                0.5|\n",
      "|3182|\"Yankee Ferry Ter...|  309|      900| 0.3433333333333333|\n",
      "|3254|  \"Soissons Landing\"|  358|     1100|0.32545454545454544|\n",
      "|3342|\"Pioneer St & Ric...|   59|      299|0.19732441471571907|\n",
      "|3477|\"39 St & 2 Ave - ...|   45|      245| 0.1836734693877551|\n",
      "|3532|\"Ditmars Blvd & 1...|   70|      407|  0.171990171990172|\n",
      "|3180|\"Brooklyn Bridge ...|  232|     1354|0.17134416543574593|\n",
      "|3423|\"West Drive & Pro...|  367|     2463|0.14900527811611855|\n",
      "|3636|\"Expansion Wareho...|    1|        8|              0.125|\n",
      "|3302|\"Columbus Ave & W...|   74|      598|0.12374581939799331|\n",
      "|3120|\"Center Blvd & Bo...|   74|      622| 0.1189710610932476|\n",
      "|3514|\"Astoria Park S &...|   34|      299|0.11371237458193979|\n",
      "|3479|      \"Picnic Point\"|   77|      712|0.10814606741573034|\n",
      "|3594|\"Montgomery St & ...|    9|       87|0.10344827586206896|\n",
      "|3524|    \"19 St & 24 Ave\"|   24|      249| 0.0963855421686747|\n",
      "|3349|\"Grand Army Plaza...|  237|     2570|0.09221789883268483|\n",
      "|3333|\"Columbia St & Lo...|    5|       55|0.09090909090909091|\n",
      "|3354|\"3 St & Prospect ...|  142|     1572|0.09033078880407125|\n",
      "|3607|    \"31 Ave & 14 St\"|   10|      113|0.08849557522123894|\n",
      "+----+--------------------+-----+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cycles: org.apache.spark.sql.DataFrame = [id: bigint, trips: int]\n",
       "gx_v: org.apache.spark.sql.DataFrame = [id: bigint, location: string]\n",
       "cycles_loc: org.apache.spark.sql.DataFrame = [id: bigint, location: string ... 1 more field]\n",
       "out_degree: org.apache.spark.sql.DataFrame = [id: string, outDegree: int]\n",
       "cycles_loc_out: org.apache.spark.sql.DataFrame = [id: bigint, location: string ... 2 more fields]\n",
       "df_output: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: bigint, location: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Use aggregateMessages to calculate the number of trips that start and end at the same vertex (for each vertex)\n",
    "//Convert the resulting (VertexRDD) to a DataFrame\n",
    "val cycles = gx.aggregateMessages[Int](ec => if (ec.srcAttr == ec.dstAttr) ec.sendToSrc(1), (x,y) => x+y).toDF(\"id\",\"trips\")\n",
    "\n",
    "//Using join (and select), add the location of the station column to the df\n",
    "val gx_v = gx.vertices.toDF(\"id\",\"location\") //dataframe of vertices\n",
    "val cycles_loc = cycles.join(gx_v, Seq(\"id\"), \"left\").select(\"id\",\"location\",\"trips\")\n",
    "\n",
    "//Join this df to the out degrees df created earlier\n",
    "val out_degree = g.outDegrees //dataframe of outdegrees\n",
    "val cycles_loc_out = cycles_loc.join(out_degree, Seq(\"id\"), \"left\")\n",
    "\n",
    "//Divide the same trips column by the out degrees column and select the appropriate rows\n",
    "//Sort the resulting df by this proportion in descending order\n",
    "val df_output = cycles_loc_out.withColumn(\"prop\", $\"trips\"/$\"outDegree\").orderBy(desc(\"prop\"))\n",
    "\n",
    "df_output.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">STEP 5: Create a new graph that contains all edges except for those between the same station</span>\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_edges: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [src: string, dst: string ... 1 more field]\n",
       "new_g: org.graphframes.GraphFrame = GraphFrame(v:[id: string, location: string], e:[src: string, dst: string ... 1 more field])\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val new_edges = g.edges.filter(\"src != dst\")\n",
    "val new_g = GraphFrame(vertices,new_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">STEP 6: Calculate the average duration between every pair of stations</span>\n",
    "<br><br>\n",
    "<li>use the new graph from step 5 for this</li>\n",
    "<li>I'll let you figure this out but this should be really easy (think SQL)</li>\n",
    "<pre>\n",
    "+----+----+------------------+\n",
    "| src| dst|                 m|\n",
    "+----+----+------------------+\n",
    "| 504| 350| 772.7647058823529|\n",
    "| 433| 527| 532.9677419354839|\n",
    "| 434| 470|316.52272727272725|\n",
    "| 438| 151|  546.195652173913|\n",
    "| 445| 507| 553.3947368421053|\n",
    "|2021| 446| 827.6904761904761|\n",
    "| 116| 518| 1115.857142857143|\n",
    "|3435| 358| 895.6666666666666|\n",
    "|3402|3414| 634.1666666666666|\n",
    "| 498| 495| 801.2272727272727|\n",
    "|3637| 418|             889.7|\n",
    "| 380|3260|419.42105263157896|\n",
    "|3360| 507|            1442.0|\n",
    "| 326| 247|             713.0|\n",
    "|3358| 467| 500.6666666666667|\n",
    "|3164| 457|502.97241379310344|\n",
    "| 498| 528| 434.3207547169811|\n",
    "| 405|3256| 843.2168674698795|\n",
    "| 477|2000|2672.3333333333335|\n",
    "|3226|3163| 686.4444444444445|\n",
    "+----+----+------------------+\n",
    "only showing top 20 rows\n",
    "<pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------------------+\n",
      "| src| dst|                 m|\n",
      "+----+----+------------------+\n",
      "|3417|3377| 418.3333333333333|\n",
      "|3467| 502| 784.7058823529412|\n",
      "| 341| 311|1655.6610169491526|\n",
      "|3407|2002|            1539.0|\n",
      "| 161|3435| 585.3466666666667|\n",
      "|3090| 433|            1415.0|\n",
      "| 490| 450| 479.7047619047619|\n",
      "| 237| 496|             468.5|\n",
      "|3542|3511|             558.5|\n",
      "|2009|3461|          654.5625|\n",
      "| 339|2008|1464.6363636363637|\n",
      "|3259| 526| 687.4615384615385|\n",
      "| 326| 483|270.91954022988506|\n",
      "|3438|3147|307.68333333333334|\n",
      "|3139|3135| 525.5714285714286|\n",
      "| 284| 487| 791.1666666666666|\n",
      "|3158|3295|            1039.0|\n",
      "| 417| 307|             734.0|\n",
      "| 342| 307|504.26190476190476|\n",
      "|3428| 435| 356.9760479041916|\n",
      "+----+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mean_durations: org.apache.spark.sql.DataFrame = [src: string, dst: string ... 1 more field]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mean_durations = new_g.edges.groupBy(\"src\",\"dst\").mean(\"dur\").withColumnRenamed(\"avg(dur)\",\"m\")\n",
    "mean_durations.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----------------+\n",
      "|src|dst|                m|\n",
      "+---+---+-----------------+\n",
      "|504|350|772.7647058823529|\n",
      "+---+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//plugging in any (src,dst) value from the sample output provided, we get the same mean duration. \n",
    "// for example, we get the same output for the first row in the sample output\n",
    "mean_durations.filter($\"src\" === 504).filter($\"dst\" === 350).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">STEP 7: Important stations</span><br><br>\n",
    "Citibike wants to figure out how best to deploy its workers in checking whether a station is over-full (too many bikes) or needs more bikes. It figures that the best way to do this is to find out which stations are the most important in terms of flows:\n",
    "<li>A station that has high bike returns and is connected to other stations with high bike returns is more likely to have too many bikes in its station and therefore should be monitored more often</li>\n",
    "<li>A station that has high bike pickups and is connected to other stations with high bike pickups is more likely to be short of bikes and therefore should be monitored more often</li>\n",
    "<li>Calculate the propensities for over-fullness and emptiness for every station</li>\n",
    "<li>Report the 5 most important stations for over-fullness (use pageRank on the graph)</li>\n",
    "<li>Report the 5 most important stations for emptiness (reverse all the edges on the graph and use pageRank)</li>\n",
    "<li>Your results (Don't worry about the meaning of location names!):</li>\n",
    "<li>Note: Assume a reset_probability of 0.15 and a tolerance of .0001 if you want the same results as mine</li>\n",
    "<pre>\n",
    "+---+--------------------+------------------+\n",
    "| id|            location|          pagerank|\n",
    "+---+--------------------+------------------+\n",
    "|519|\"Pershing Square ...| 4.930887390071603|\n",
    "|426|\"West St & Chambe...|3.7410934274030576|\n",
    "|402|\"Broadway & E 22 St\"|  3.58520147183096|\n",
    "|497|\"E 17 St & Broadway\"| 3.537658018512581|\n",
    "|435|   \"W 21 St & 6 Ave\"| 3.438585855241344|\n",
    "+---+--------------------+------------------+\n",
    "\n",
    "+----+--------------------+------------------+\n",
    "|  id|            location|          pagerank|\n",
    "+----+--------------------+------------------+\n",
    "|3197|      \"Hs Don't Use\"| 5.710640869520747|\n",
    "| 519|\"Pershing Square ...| 5.012823444592195|\n",
    "|3480|      \"WS Don't Use\"| 4.272284643284593|\n",
    "| 402|\"Broadway & E 22 St\"|3.4515211069038183|\n",
    "| 497|\"E 17 St & Broadway\"|3.3347259745457443|\n",
    "+----+--------------------+------------------+\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------------------+\n",
      "| id|            location|          pagerank|\n",
      "+---+--------------------+------------------+\n",
      "|519|\"Pershing Square ...|4.9308873900715895|\n",
      "|426|\"West St & Chambe...| 3.741093427403052|\n",
      "|402|\"Broadway & E 22 St\"|3.5852014718309544|\n",
      "|497|\"E 17 St & Broadway\"|3.5376580185125768|\n",
      "|435|   \"W 21 St & 6 Ave\"| 3.438585855241336|\n",
      "+---+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ranks: org.graphframes.GraphFrame = GraphFrame(v:[id: string, location: string ... 1 more field], e:[src: string, dst: string ... 2 more fields])\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ranks = g.pageRank.resetProbability(0.15).tol(0.0001).run() //takes long time to run\n",
    "ranks.vertices.orderBy(desc(\"pagerank\")).limit(5).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------------+\n",
      "|  id|            location|          pagerank|\n",
      "+----+--------------------+------------------+\n",
      "|3197|      \"Hs Don't Use\"|5.7106408695207485|\n",
      "| 519|\"Pershing Square ...| 5.012823444592195|\n",
      "|3480|      \"WS Don't Use\"| 4.272284643284594|\n",
      "| 402|\"Broadway & E 22 St\"| 3.451521106903816|\n",
      "| 497|\"E 17 St & Broadway\"| 3.334725974545743|\n",
      "+----+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inverted_edges: org.apache.spark.sql.DataFrame = [src: string, dst: string ... 1 more field]\n",
       "i_g: org.graphframes.GraphFrame = GraphFrame(v:[id: string, location: string], e:[src: string, dst: string ... 1 more field])\n",
       "ranks_inv: org.graphframes.GraphFrame = GraphFrame(v:[id: string, location: string ... 1 more field], e:[src: string, dst: string ... 2 more fields])\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inverted_edges = g.edges.withColumn(\"swap\",$\"dst\").withColumn(\"dst\",$\"src\").withColumn(\"src\",$\"swap\").drop($\"swap\")\n",
    "val i_g = GraphFrame(vertices,inverted_edges)  \n",
    "\n",
    "val ranks_inv = i_g.pageRank.resetProbability(0.15).tol(0.0001).run() //takes long time to run\n",
    "ranks_inv.vertices.orderBy(desc(\"pagerank\")).limit(5).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">STEP 8: Calculate the clustering coefficient of every station</span><br><br>\n",
    "\n",
    "<li>And report the top 20 stations by clustering coefficient</li>\n",
    "<pre>\n",
    "+----+--------------------+------------------+\n",
    "|  id|            location|             coeff|\n",
    "+----+--------------------+------------------+\n",
    "|3040|     \"GOW Tech Shop\"|               1.0|\n",
    "|3639|        \"Harborside\"|               1.0|\n",
    "|3192|\"Liberty Light Rail\"|               1.0|\n",
    "|3485| \"NYCBS Depot - RIS\"|               1.0|\n",
    "|3647|    \"48 Ave & 30 Pl\"|               1.0|\n",
    "|3279|       \"Dixon Mills\"|               1.0|\n",
    "|3186|     \"Grove St PATH\"|               1.0|\n",
    "| 153|   \"E 40 St & 5 Ave\"|               1.0|\n",
    "| 339|\"Avenue D & E 12 St\"| 0.877201420748853|\n",
    "|3464|\"W 37 St & Broadway\"|0.8679573382796197|\n",
    "| 247|\"Perry St & Bleec...|0.8602079768329604|\n",
    "|3175|\"W 70 St & Amster...|0.8592469808193227|\n",
    "|3176|\"W 64 St & West E...|0.8568452539928423|\n",
    "|3623|\"W 120 St & Clare...|0.8549019607843137|\n",
    "|3491|  \"E 118 St & 1 Ave\"| 0.854122621564482|\n",
    "| 266| \"Avenue D & E 8 St\"| 0.849218980253463|\n",
    "|3441|   \"10 Hudson Yards\"|0.8482701509017299|\n",
    "|3646|    \"35 Ave & 10 St\"|0.8333333333333334|\n",
    "|3642|\"E 98 St & Lexing...|             0.832|\n",
    "| 444|\"Broadway & W 24 St\"|0.8283229697508064|\n",
    "+----+--------------------+------------------+\n",
    "only showing top 20 rows\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------------+\n",
      "|  id|            location|             coeff|\n",
      "+----+--------------------+------------------+\n",
      "|3647|    \"48 Ave & 30 Pl\"|               1.0|\n",
      "|3639|        \"Harborside\"|               1.0|\n",
      "|3192|\"Liberty Light Rail\"|               1.0|\n",
      "|3485| \"NYCBS Depot - RIS\"|               1.0|\n",
      "|3279|       \"Dixon Mills\"|               1.0|\n",
      "| 153|   \"E 40 St & 5 Ave\"|               1.0|\n",
      "|3186|     \"Grove St PATH\"|               1.0|\n",
      "|3040|     \"GOW Tech Shop\"|               1.0|\n",
      "| 339|\"Avenue D & E 12 St\"| 0.877201420748853|\n",
      "|3464|\"W 37 St & Broadway\"|0.8679573382796197|\n",
      "| 247|\"Perry St & Bleec...|0.8602079768329604|\n",
      "|3175|\"W 70 St & Amster...|0.8592469808193227|\n",
      "|3176|\"W 64 St & West E...|0.8568452539928423|\n",
      "|3623|\"W 120 St & Clare...|0.8549019607843137|\n",
      "|3491|  \"E 118 St & 1 Ave\"| 0.854122621564482|\n",
      "| 266| \"Avenue D & E 8 St\"| 0.849218980253463|\n",
      "|3441|   \"10 Hudson Yards\"|0.8482701509017299|\n",
      "|3646|    \"35 Ave & 10 St\"|0.8333333333333334|\n",
      "|3642|\"E 98 St & Lexing...|             0.832|\n",
      "| 444|\"Broadway & W 24 St\"|0.8283229697508064|\n",
      "+----+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "triangles: org.apache.spark.sql.DataFrame = [count: bigint, id: string ... 1 more field]\n",
       "degrees: org.apache.spark.sql.DataFrame = [id: string, degree: int]\n",
       "possible: org.apache.spark.sql.DataFrame = [id: string, degree: int ... 1 more field]\n",
       "joined: org.apache.spark.sql.DataFrame = [id: string, count: bigint ... 3 more fields]\n",
       "coeff: org.apache.spark.sql.DataFrame = [id: string, count: bigint ... 4 more fields]\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val triangles = g.triangleCount.run()//Get the number of triangles each vertex belongs to\n",
    "val degrees = make_undirected_graph(g).degrees //Get the number of adjacent vertices for each vertex\n",
    "val possible = degrees.withColumn(\"possible\",col(\"degree\")*(col(\"degree\")-1)/lit(2)) //Calculate possible triangles\n",
    "val joined = triangles.select(\"id\",\"count\").join(possible,Seq(\"id\"))\n",
    "    .join(vertices, Seq(\"id\"))\n",
    "val coeff = joined.withColumn(\"coeff\",col(\"count\")/col(\"possible\"))\n",
    "coeff.select(\"id\",\"location\",\"coeff\").orderBy(desc(\"coeff\")).limit(20).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
